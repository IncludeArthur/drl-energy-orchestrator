{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13051c45-bd22-451d-830b-9fbd218e65f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-18 11:44:40.724007: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-18 11:44:40.726614: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-18 11:44:40.808927: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-18 11:44:40.808958: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-18 11:44:40.811335: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-18 11:44:40.822950: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-18 11:44:40.826011: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-18 11:44:41.712474: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import seaborn as sns\n",
    "from env_utils import PDUSession\n",
    "from nfv_allocation_cpu_env import NfvAllocEnv\n",
    "from nfv_allocation_cpu_env_duration import NfvAllocEnvDuration\n",
    "from nfv_allocation_cpu_env_rew import NfvAllocEnvRew\n",
    "from stable_baselines3 import PPO, A2C, DQN, TD3\n",
    "from sb3_contrib import MaskablePPO, RecurrentPPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.vec_env import VecNormalize\n",
    "from sb3_contrib.common.maskable.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70e37292-15df-4b1f-ad63-abf9699f4910",
   "metadata": {},
   "outputs": [],
   "source": [
    "qi_dict = {3:0.3, 5:0.4, 9:0.3}\n",
    "#qi_dict = {3:0.6, 5:0.3, 9:0.1}\n",
    "env_par={'config_file': 'nuc_host_models.json', 'obs_metric':'power', 'rw_metric':'power', 'flat_lerr': False, 'dt_scale': 1.0, 'duration_mean':40, 'duration_scale':5, 'qi_dict': qi_dict}\n",
    "#env_par={'config_file': 'nuc_host_models-4.json', 'dt_scale': 1, 'duration_mean':40, 'duration_scale':5, 'qi_dict': qi_dict}\n",
    "\n",
    "#env = NfvAllocEnv(**env_par)\n",
    "#env = NfvAllocEnvDuration(**env_par)\n",
    "env = NfvAllocEnvRew(**env_par)\n",
    "\n",
    "seed = None\n",
    "gamma = 0.05\n",
    "n_steps = 10_000\n",
    "\n",
    "env.set_gamma(gamma)\n",
    "\n",
    "step_data = []\n",
    "run_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8683e20f-b170-4515-ba9e-90891270d1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "drl_model = MaskablePPO.load(path='saved models/PPO_rew10_net128_nodur_scale1.5_env8_nuc_power_qi359_p343')\n",
    "#drl_model = RecurrentPPO.load('saved models/RecurrentPPO_dur_scale1.5_env8_random3_power_llearn_flat_npseedNone_g05_qi359_p343')\n",
    "#drl_model = DQN.load('saved models/DQN_dur_scale1.5_env8_random_power_llearn_flat_npseedNone_g1_qi359_p343')\n",
    "drl_model_cpu = MaskablePPO.load(path='saved models/PPO_rew10_net128_nodur_scale1.5_env8_nuc_cpu_qi359_p343')\n",
    "\n",
    "f = open('5qi_table.json')\n",
    "qi_table = json.load(f)\n",
    "\n",
    "def drl_policy(obs, mask):\n",
    "    action, _states = drl_model.predict(obs, action_masks=mask, deterministic=True)\n",
    "    return action\n",
    "    \n",
    "def drl_policy_nomask(obs):\n",
    "    action, _states = drl_model.predict(obs, deterministic=True)\n",
    "    return action\n",
    "\n",
    "def recurrent_drl_policy(obs, lstm_states):\n",
    "    action, lstm_states = drl_model.predict(obs, state=lstm_states, episode_start=episode_starts, deterministic=True)\n",
    "    return action, lstm_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c1b3263-8171-4a89-a40a-1cb1c46a5f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return the host with the lowest current energy that is not full. How to handle on/off nodes?\n",
    "def energy_greedy_policy(obs, action_mask):\n",
    "    # energy greedy alway choose the cloud?\n",
    "    action = 0\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e648ea59-33c8-4488-b819-96cf15e9e2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return the host with the lowest latency that is not full. How to handle on/off nodes?\n",
    "def latency_greedy_policy(obs, action_mask):\n",
    "    available_hosts = np.argwhere(mask).flatten()\n",
    "    #print('available hosts: ',available_hosts)\n",
    "    latencies = obs[:,3]\n",
    "    #print('latencies: ', latencies)\n",
    "    action = available_hosts[np.argmin(latencies[available_hosts])]\n",
    "    #print('action: ',action)\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c70d3dbf-c7a2-4db5-8813-246acc254da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_action_policy(obs, action_mask):\n",
    "    available_hosts = np.argwhere(mask).flatten()\n",
    "    action = available_hosts[np.random.randint(available_hosts.size)]\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62463963-d5b4-4edf-adec-236001e3ab11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose the host with maximum latency between the ones that satisfy the required latency otherwise minimize latency error\n",
    "def latency_smart_policy(obs, action_mask):\n",
    "    available_hosts = np.argwhere(mask).flatten()\n",
    "    #print('available hosts: ',available_hosts)\n",
    "    latencies = obs[:,3]\n",
    "    #print('latencies: ', latencies)\n",
    "    #required_lat = PDUSession.latencies[int(obs[0,4])]\n",
    "    req_qi = int(obs[0,4])\n",
    "    #required_lat = qi_table[str(req_qi)][\"delay\"]\n",
    "    required_lat = req_qi #NOTE: I canged the observation from the 5qi to the latency\n",
    "    #print('required lat: ', required_lat)\n",
    "    \n",
    "    av_latencies = latencies[available_hosts]\n",
    "    good_latencies = np.where(av_latencies <= required_lat)[0]\n",
    "    #print('good latencies: ', good_latencies)\n",
    "    if good_latencies.size != 0:\n",
    "        #print('smart!')\n",
    "        action = available_hosts[good_latencies[np.argmax(latencies[good_latencies])]]\n",
    "    else:\n",
    "        action = available_hosts[np.argmin(latencies[available_hosts])]\n",
    "    #print('action: ',action)\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9712ae06-5df1-46d2-ba00-b3415c225f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81f84e38890440309c6c5913d6eca13a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Error: Unexpected observation shape (1, 7, 7) for Box environment, please use (7, 8) or (n_env, 7, 8) for the observation shape.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(n_steps)):\n\u001b[1;32m     17\u001b[0m     mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(envs\u001b[38;5;241m.\u001b[39menv_method(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maction_masks\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m---> 18\u001b[0m     action \u001b[38;5;241m=\u001b[39m \u001b[43mdrl_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction_masks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     qi\u001b[38;5;241m=\u001b[39m envs\u001b[38;5;241m.\u001b[39menv_method(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_current_qi\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     20\u001b[0m     choices\u001b[38;5;241m.\u001b[39mappend([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrl power\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mint\u001b[39m(qi[\u001b[38;5;241m0\u001b[39m]), \u001b[38;5;28mint\u001b[39m(action[\u001b[38;5;241m0\u001b[39m])])\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sb3_contrib/ppo_mask/ppo_mask.py:380\u001b[0m, in \u001b[0;36mMaskablePPO.predict\u001b[0;34m(self, observation, state, episode_start, deterministic, action_masks)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    361\u001b[0m     observation: np\u001b[38;5;241m.\u001b[39mndarray,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    365\u001b[0m     action_masks: Optional[np\u001b[38;5;241m.\u001b[39mndarray] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    366\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[np\u001b[38;5;241m.\u001b[39mndarray, Optional[Tuple[np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]]]:\n\u001b[1;32m    367\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;124;03m    Get the policy action from an observation (and optional hidden state).\u001b[39;00m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;124;03m    Includes sugar-coating to handle different observations (e.g. normalizing images).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;124;03m        (used in recurrent policies)\u001b[39;00m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 380\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepisode_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction_masks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction_masks\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sb3_contrib/common/maskable/policies.py:287\u001b[0m, in \u001b[0;36mMaskableActorCriticPolicy.predict\u001b[0;34m(self, observation, state, episode_start, deterministic, action_masks)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;66;03m# Switch to eval mode (this affects batch norm / dropout)\u001b[39;00m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_training_mode(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 287\u001b[0m observation, vectorized_env \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobs_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m th\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    290\u001b[0m     actions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict(observation, deterministic\u001b[38;5;241m=\u001b[39mdeterministic, action_masks\u001b[38;5;241m=\u001b[39maction_masks)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/stable_baselines3/common/policies.py:270\u001b[0m, in \u001b[0;36mBaseModel.obs_to_tensor\u001b[0;34m(self, observation)\u001b[0m\n\u001b[1;32m    266\u001b[0m     observation \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(observation)\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(observation, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;66;03m# Dict obs need to be handled separately\u001b[39;00m\n\u001b[0;32m--> 270\u001b[0m     vectorized_env \u001b[38;5;241m=\u001b[39m \u001b[43mis_vectorized_observation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobservation_space\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;66;03m# Add batch dimension if needed\u001b[39;00m\n\u001b[1;32m    272\u001b[0m     observation \u001b[38;5;241m=\u001b[39m observation\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation_space\u001b[38;5;241m.\u001b[39mshape))  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/stable_baselines3/common/utils.py:399\u001b[0m, in \u001b[0;36mis_vectorized_observation\u001b[0;34m(observation, observation_space)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m space_type, is_vec_obs_func \u001b[38;5;129;01min\u001b[39;00m is_vec_obs_func_dict\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    398\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(observation_space, space_type):\n\u001b[0;32m--> 399\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mis_vec_obs_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobservation_space\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[operator]\u001b[39;00m\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;66;03m# for-else happens if no break is called\u001b[39;00m\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError: Cannot determine if the observation is vectorized with the space type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobservation_space\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/stable_baselines3/common/utils.py:266\u001b[0m, in \u001b[0;36mis_vectorized_box_observation\u001b[0;34m(observation, observation_space)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 266\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    267\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError: Unexpected observation shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobservation\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    268\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBox environment, please use \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobservation_space\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    269\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor (n_env, \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m) for the observation shape.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mstr\u001b[39m, observation_space\u001b[38;5;241m.\u001b[39mshape)))\n\u001b[1;32m    270\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Error: Unexpected observation shape (1, 7, 7) for Box environment, please use (7, 8) or (n_env, 7, 8) for the observation shape."
     ]
    }
   ],
   "source": [
    "#DRL POWER\n",
    "envs = DummyVecEnv([lambda: NfvAllocEnvRew(**env_par)])\n",
    "envs = VecNormalize(envs, norm_reward=False) \n",
    "\n",
    "drl_lat_errors = []\n",
    "drl_ppmbit = []\n",
    "choices = []\n",
    "drl_rewards = []\n",
    "tot_rew = 0\n",
    "\n",
    "envs.seed(seed)\n",
    "obs = envs.reset()\n",
    "#info = envs.reset_infos\n",
    "#print(info)\n",
    "\n",
    "for step in tqdm(range(n_steps)):\n",
    "    mask = np.array(envs.env_method(\"action_masks\"))\n",
    "    action = drl_model.predict(obs, action_masks=mask)\n",
    "    qi= envs.env_method(\"get_current_qi\")\n",
    "    choices.append([\"drl power\", int(qi[0]), int(action[0])])\n",
    "    obs, reward, dones, info = envs.step(action)\n",
    "    tot_rew += reward[0]\n",
    "    drl_rewards.append(reward[0])\n",
    "    drl_lat_errors.append(info[0]['latency_error'])\n",
    "    drl_ppmbit.append(info[0]['power_per_mbit'])\n",
    "    step_data.append([\"drl power\", step, info[0]['power_per_mbit'], reward[0]])\n",
    "    \n",
    "run_data.append([\"drl power\", np.count_nonzero(drl_lat_errors)/n_steps*100, tot_rew])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5c8dce-0e75-4b51-8d9c-10ff707da0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DRL CPU\n",
    "#env_par_cpu={'config_file': 'random_host_models.json', 'obs_metric':'cpu', 'rw_metric':'power', 'flat_lerr': False, 'dt_scale': 1.5, 'duration_mean':40, 'duration_scale':5, 'qi_dict': qi_dict}\n",
    "env_par_cpu = env_par\n",
    "env_par_cpu['obs_metric'] = 'cpu'\n",
    "print(env_par_cpu)\n",
    "envs = DummyVecEnv([lambda: NfvAllocEnvRew(**env_par_cpu)])\n",
    "envs = VecNormalize(envs, norm_reward=False) \n",
    "\n",
    "drl_lat_errors = []\n",
    "drl_ppmbit = []\n",
    "#choices = []\n",
    "drl_rewards = []\n",
    "tot_rew = 0\n",
    "\n",
    "envs.seed(seed)\n",
    "obs = envs.reset()\n",
    "#info = envs.reset_infos\n",
    "#print(info)\n",
    "\n",
    "for step in tqdm(range(n_steps)):\n",
    "    mask = np.array(envs.env_method(\"action_masks\"))\n",
    "    action = drl_model_cpu.predict(obs, action_masks=mask)\n",
    "    qi= envs.env_method(\"get_current_qi\")\n",
    "    choices.append([\"drl cpu\", int(qi[0]), int(action[0])])\n",
    "    obs, reward, dones, info = envs.step(action)\n",
    "    tot_rew += reward[0]\n",
    "    drl_rewards.append(reward[0])\n",
    "    drl_lat_errors.append(info[0]['latency_error'])\n",
    "    drl_ppmbit.append(info[0]['power_per_mbit'])\n",
    "    step_data.append([\"drl cpu\", step, info[0]['power_per_mbit'], reward[0]])\n",
    "    \n",
    "run_data.append([\"drl cpu\", np.count_nonzero(drl_lat_errors)/n_steps*100, tot_rew])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb09e3a-4fbf-4cd9-a66f-14289c610212",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LATENCY GREEDY\n",
    "#n_steps = 1000\n",
    "lg_lat_errors = []\n",
    "lg_ppmbit = []\n",
    "tot_rew = 0\n",
    "\n",
    "obs, info = env.reset(seed=seed)\n",
    "\n",
    "for step in tqdm(range(n_steps)):\n",
    "    mask = env.action_masks()\n",
    "    action = latency_greedy_policy(obs, mask)\n",
    "    obs, reward, _, _, info = env.step(action)\n",
    "    tot_rew += reward\n",
    "    lg_lat_errors.append(info['latency_error'])\n",
    "    lg_ppmbit.append(info['power_per_mbit'])\n",
    "    step_data.append([\"latency greedy\", step, info['power_per_mbit'], reward])\n",
    "    \n",
    "run_data.append([\"latency greedy\", np.count_nonzero(lg_lat_errors)/n_steps*100, tot_rew])\n",
    "env.print_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f981091-bb06-4173-8151-adb537ebce58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ENERGY GREEDY\n",
    "#n_steps = 1000\n",
    "eg_lat_errors = []\n",
    "eg_ppmbit = []\n",
    "tot_rew = 0\n",
    "\n",
    "obs, info = env.reset(seed=seed)\n",
    "\n",
    "for step in tqdm(range(n_steps)):\n",
    "    mask = env.action_masks()\n",
    "    action = energy_greedy_policy(obs, mask)\n",
    "    obs, reward, _, _, info = env.step(action)\n",
    "    tot_rew += reward\n",
    "    eg_lat_errors.append(info['latency_error'])\n",
    "    eg_ppmbit.append(info['power_per_mbit'])\n",
    "    step_data.append([\"energy greedy\", step, info['power_per_mbit'], reward])\n",
    "    \n",
    "run_data.append([\"energy greedy\", np.count_nonzero(eg_lat_errors)/n_steps*100, tot_rew])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce097b4a-17bd-45e9-aabb-f41975f63021",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RANDOM ACTION\n",
    "#n_steps = 1000\n",
    "rand_lat_errors = []\n",
    "rand_ppmbit = []\n",
    "tot_rew = 0\n",
    "\n",
    "obs, info = env.reset(seed=seed)\n",
    "\n",
    "for step in tqdm(range(n_steps)):\n",
    "    mask = env.action_masks()\n",
    "    action = random_action_policy(obs, mask)\n",
    "    obs, reward, _, _, info = env.step(action)\n",
    "    tot_rew += reward\n",
    "    rand_lat_errors.append(info['latency_error'])\n",
    "    rand_ppmbit.append(info['power_per_mbit'])\n",
    "    step_data.append([\"random action\", step, info['power_per_mbit'], reward])\n",
    "    \n",
    "run_data.append([\"random action\", np.count_nonzero(rand_lat_errors)/n_steps*100, tot_rew])\n",
    "#env.print_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012492b9-569a-42e3-8054-be66b85805e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LATENCY SMART\n",
    "#n_steps = 1000\n",
    "ls_lat_errors = []\n",
    "ls_ppmbit = []\n",
    "tot_rew = 0\n",
    "\n",
    "obs, info = env.reset(seed=seed)\n",
    "\n",
    "for step in tqdm(range(n_steps)):\n",
    "    mask = env.action_masks()\n",
    "    action = latency_smart_policy(obs, mask)\n",
    "    obs, reward, _, _, info = env.step(action)\n",
    "    tot_rew += reward\n",
    "    ls_lat_errors.append(info['latency_error'])\n",
    "    ls_ppmbit.append(info['power_per_mbit'])\n",
    "    step_data.append([\"latency smart\", step, info['power_per_mbit'], reward])\n",
    "    \n",
    "run_data.append([\"latency smart\", np.count_nonzero(ls_lat_errors)/n_steps*100, tot_rew])\n",
    "env.print_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40c8c46-5556-4676-b8b5-d9f939405b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_df = pd.DataFrame(step_data, columns=['algorithm', 'step','power', 'reward'])\n",
    "run_df = pd.DataFrame(run_data, columns=['algorithm', 'error percent', 'episode reward'])\n",
    "choices_df = pd.DataFrame(choices, columns=['metric','5qi', 'host'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb8143a-2a72-4b57-9952-8f276851cd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=step_df, y=\"power\", hue=\"algorithm\", showfliers=False)\n",
    "plt.xlabel(\"algorithm\")\n",
    "plt.ylabel(\"power consumption [W / Mbit]\")\n",
    "plt.grid()\n",
    "plt.legend( loc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c29052-b4b3-4d68-aaa6-88b96f78f02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax=sns.barplot(data=run_df, y=\"error percent\", hue=\"algorithm\", linewidth=.5, edgecolor=\"0\")\n",
    "plt.ylabel(\"latency error %\")\n",
    "plt.xlabel(\"algorithm\")\n",
    "plt.grid()\n",
    "#plt.yscale('log')\n",
    "ax.legend_.set_title(None)\n",
    "for i in ax.containers:\n",
    "    ax.bar_label(i,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bae8ea-646c-4f25-a1db-b44de476f164",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.barplot(data=run_df, y=\"episode reward\", hue=\"algorithm\", linewidth=.5, edgecolor=\"0\")\n",
    "plt.xlabel(\"algorithm\")\n",
    "plt.legend(loc=3)\n",
    "plt.grid()\n",
    "ax.legend_.set_title(None)\n",
    "for i in ax.containers:\n",
    "    ax.bar_label(i,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d46828-5fdd-4b30-ac5c-2cac82d981c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ccp = choices_df.loc[choices_df['metric'] == \"drl power\"]\n",
    "ccc = choices_df.loc[choices_df['metric'] == 'drl cpu']\n",
    "cdf_p = pd.crosstab(ccp['host'], ccp['5qi'])#.div(len(choices_df))\n",
    "cdf_c = pd.crosstab(ccc['host'], ccc['5qi'])#.div(len(choices_df))\n",
    "\n",
    "f, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "sns.heatmap(cdf_p, annot=True, fmt='g',cmap=\"Greens\", linewidths=.5, linecolor='0', ax=axes[0]).set_title(\"drl power\")\n",
    "sns.heatmap(cdf_c, annot=True, fmt='g',cmap=\"Greens\", linewidths=.5, linecolor='0', ax=axes[1]).set_title(\"drl cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc26b48-0765-4d94-ac57-d18f17a12199",
   "metadata": {},
   "source": [
    "Latency Smart algorithm performs better in this case because the host with the highest latency inside the requirements also has the lowest power consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f809b81-7da3-4b56-9620-c4015e1a23d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(drl_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef01ddf5-e067-4f41-bc2e-2b35e445a942",
   "metadata": {},
   "outputs": [],
   "source": [
    "drl_model.get_parameters()['policy']['action_net.weight'].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9f21a5-bde8-4f4a-97e1-a833b68a499d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sns.color_palette().as_hex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d09138-cc41-4dd7-9bde-eb777433ecd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.color_palette()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fd10fa-a3a7-4696-addc-a8af3b9b7518",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
